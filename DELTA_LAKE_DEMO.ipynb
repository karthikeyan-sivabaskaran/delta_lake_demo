{"cells":[{"cell_type":"code","source":["from pyspark.sql import Row\nl = [(1001,'Apple Mac Book', 11, 'I'),(1002,'Apple iPhone 11', 22, 'I'),(1003,'Redmi Note 4', 33, 'I'),(1004, 'Dell Inspiron', 44, 'I')]\nrdd = sc.parallelize(l)\nschemaRdd = rdd.map(lambda x: Row(product_id=int(x[0]), product_name=x[1], stocks_left=int(x[2]), row_flag=x[3]))\nproduct_df = spark.createDataFrame(schemaRdd)\ndisplay(product_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>product_id</th><th>product_name</th><th>row_flag</th><th>stocks_left</th></tr></thead><tbody><tr><td>1001</td><td>Apple Mac Book</td><td>I</td><td>11</td></tr><tr><td>1002</td><td>Apple iPhone 11</td><td>I</td><td>22</td></tr><tr><td>1003</td><td>Redmi Note 4</td><td>I</td><td>33</td></tr><tr><td>1004</td><td>Dell Inspiron</td><td>I</td><td>44</td></tr></tbody></table></div>"]}}],"execution_count":1},{"cell_type":"code","source":["database_name = 'delta_demo'\ndelta_table_name = 'product_table_delta'\nparquet_table_name = 'product_table_parquet'"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["(product_df\n  .repartition(2)\n  .write\n  .mode(\"overwrite\")\n  .format(\"parquet\")\n  .saveAsTable(f'{database_name}.{parquet_table_name}')\n)\n\n(product_df\n  .repartition(2)\n  .write\n  .mode(\"overwrite\")\n  .option(\"overwriteSchema\", True)\n  .format(\"delta\")\n  .saveAsTable(f'{database_name}.{delta_table_name}')\n)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["%sql\n\ndesc formatted delta_demo.product_table_delta"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>col_name</th><th>data_type</th><th>comment</th></tr></thead><tbody><tr><td>product_id</td><td>bigint</td><td>null</td></tr><tr><td>product_name</td><td>string</td><td>null</td></tr><tr><td>row_flag</td><td>string</td><td>null</td></tr><tr><td>stocks_left</td><td>bigint</td><td>null</td></tr><tr><td></td><td></td><td></td></tr><tr><td># Detailed Table Information</td><td></td><td></td></tr><tr><td>Database</td><td>delta_demo</td><td></td></tr><tr><td>Table</td><td>product_table_delta</td><td></td></tr><tr><td>Owner</td><td>root</td><td></td></tr><tr><td>Created Time</td><td>Sun Jun 28 07:40:09 UTC 2020</td><td></td></tr><tr><td>Last Access</td><td>Thu Jan 01 00:00:00 UTC 1970</td><td></td></tr><tr><td>Created By</td><td>Spark 2.4.5</td><td></td></tr><tr><td>Type</td><td>MANAGED</td><td></td></tr><tr><td>Provider</td><td>delta</td><td></td></tr><tr><td>Location</td><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta</td><td></td></tr><tr><td>Serde Library</td><td>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</td><td></td></tr><tr><td>InputFormat</td><td>org.apache.hadoop.mapred.SequenceFileInputFormat</td><td></td></tr><tr><td>OutputFormat</td><td>org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</td><td></td></tr></tbody></table></div>"]}}],"execution_count":4},{"cell_type":"code","source":["%fs\n\nls dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/.s3-optimization-0</td><td>.s3-optimization-0</td><td>0</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/.s3-optimization-1</td><td>.s3-optimization-1</td><td>0</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/.s3-optimization-2</td><td>.s3-optimization-2</td><td>0</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000000.crc</td><td>00000000000000000000.crc</td><td>89</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000000.json</td><td>00000000000000000000.json</td><td>3287</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000001.crc</td><td>00000000000000000001.crc</td><td>89</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000001.json</td><td>00000000000000000001.json</td><td>3414</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000002.crc</td><td>00000000000000000002.crc</td><td>91</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000002.json</td><td>00000000000000000002.json</td><td>2700</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000003.crc</td><td>00000000000000000003.crc</td><td>91</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000003.json</td><td>00000000000000000003.json</td><td>3551</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000004.crc</td><td>00000000000000000004.crc</td><td>89</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000004.json</td><td>00000000000000000004.json</td><td>4834</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000005.crc</td><td>00000000000000000005.crc</td><td>89</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000005.json</td><td>00000000000000000005.json</td><td>3956</td></tr></tbody></table></div>"]}}],"execution_count":5},{"cell_type":"code","source":["sqlCmd = f\"SELECT * FROM {database_name}.{parquet_table_name}\"\ndisplay(spark.sql(sqlCmd))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>product_id</th><th>product_name</th><th>row_flag</th><th>stocks_left</th></tr></thead><tbody><tr><td>1002</td><td>Apple iPhone 11</td><td>I</td><td>22</td></tr><tr><td>1001</td><td>Apple Mac Book</td><td>I</td><td>11</td></tr><tr><td>1004</td><td>Dell Inspiron</td><td>I</td><td>44</td></tr><tr><td>1003</td><td>Redmi Note 4</td><td>I</td><td>33</td></tr></tbody></table></div>"]}}],"execution_count":6},{"cell_type":"code","source":["sqlCmd = f\"SELECT * FROM {database_name}.{delta_table_name}\"\ndisplay(spark.sql(sqlCmd))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>product_id</th><th>product_name</th><th>row_flag</th><th>stocks_left</th></tr></thead><tbody><tr><td>1002</td><td>Apple iPhone 11</td><td>I</td><td>22</td></tr><tr><td>1001</td><td>Apple Mac Book</td><td>I</td><td>11</td></tr><tr><td>1004</td><td>Dell Inspiron</td><td>I</td><td>44</td></tr><tr><td>1003</td><td>Redmi Note 4</td><td>I</td><td>33</td></tr></tbody></table></div>"]}}],"execution_count":7},{"cell_type":"code","source":["l = [(1001,'Apple Mac Book', 'eleven', 'I'),(1002,'Apple iPhone 11', 22.52, 'I'),(1003,'Redmi Note 4', 33, 'I'),(1004, 'Dell Inspiron', 44, 'I')]\nrdd = sc.parallelize(l)\nschemaRdd = rdd.map(lambda x: Row(product_id=int(x[0]), product_name=x[1], stocks_left=str(x[2]), row_flag=x[3]))\ntype_changed_product_df = spark.createDataFrame(schemaRdd)\ndisplay(type_changed_product_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>product_id</th><th>product_name</th><th>row_flag</th><th>stocks_left</th></tr></thead><tbody><tr><td>1001</td><td>Apple Mac Book</td><td>I</td><td>eleven</td></tr><tr><td>1002</td><td>Apple iPhone 11</td><td>I</td><td>22.52</td></tr><tr><td>1003</td><td>Redmi Note 4</td><td>I</td><td>33</td></tr><tr><td>1004</td><td>Dell Inspiron</td><td>I</td><td>44</td></tr></tbody></table></div>"]}}],"execution_count":8},{"cell_type":"code","source":["(type_changed_product_df\n  .repartition(2)\n  .write\n  .mode(\"append\")\n  .format(\"parquet\")\n  .saveAsTable(f'{database_name}.{parquet_table_name}')\n)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["(type_changed_product_df\n  .repartition(2)\n  .write\n  .mode(\"append\")\n  .format(\"delta\")\n  .saveAsTable(f'{database_name}.{delta_table_name}')\n)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     62</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 63</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     64</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    327</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}.\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-fg\">--&gt; 328</span><span class=\"ansi-red-fg\">                     format(target_id, &#34;.&#34;, name), value)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    329</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-red-fg\">Py4JJavaError</span>: An error occurred while calling o1955.saveAsTable.\n: org.apache.spark.sql.AnalysisException: Failed to merge fields &#39;stocks_left&#39; and &#39;stocks_left&#39;. Failed to merge incompatible data types LongType and DoubleType;;\n\tat com.databricks.sql.transaction.tahoe.schema.SchemaUtils$$anonfun$18.apply(SchemaUtils.scala:685)\n\tat com.databricks.sql.transaction.tahoe.schema.SchemaUtils$$anonfun$18.apply(SchemaUtils.scala:674)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)\n\tat com.databricks.sql.transaction.tahoe.schema.SchemaUtils$.com$databricks$sql$transaction$tahoe$schema$SchemaUtils$$merge$1(SchemaUtils.scala:674)\n\tat com.databricks.sql.transaction.tahoe.schema.SchemaUtils$.mergeSchemas(SchemaUtils.scala:750)\n\tat com.databricks.sql.transaction.tahoe.schema.ImplicitMetadataOperation$class.updateMetadata(ImplicitMetadataOperation.scala:64)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDelta.updateMetadata(WriteIntoDelta.scala:50)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDelta.write(WriteIntoDelta.scala:91)\n\tat com.databricks.sql.transaction.tahoe.commands.CreateDeltaTableCommand$$anonfun$run$2.apply(CreateDeltaTableCommand.scala:119)\n\tat com.databricks.sql.transaction.tahoe.commands.CreateDeltaTableCommand$$anonfun$run$2.apply(CreateDeltaTableCommand.scala:93)\n\tat com.databricks.logging.UsageLogging$$anonfun$recordOperation$1.apply(UsageLogging.scala:428)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:238)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:233)\n\tat com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:18)\n\tat com.databricks.logging.UsageLogging$class.withAttributionTags(UsageLogging.scala:275)\n\tat com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:18)\n\tat com.databricks.logging.UsageLogging$class.recordOperation(UsageLogging.scala:409)\n\tat com.databricks.spark.util.PublicDBLogging.recordOperation(DatabricksSparkUsageLogger.scala:18)\n\tat com.databricks.spark.util.PublicDBLogging.recordOperation0(DatabricksSparkUsageLogger.scala:55)\n\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:98)\n\tat com.databricks.spark.util.UsageLogger$class.recordOperation(UsageLogger.scala:67)\n\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:67)\n\tat com.databricks.spark.util.UsageLogging$class.recordOperation(UsageLogger.scala:342)\n\tat com.databricks.sql.transaction.tahoe.commands.CreateDeltaTableCommand.recordOperation(CreateDeltaTableCommand.scala:45)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging$class.recordDeltaOperation(DeltaLogging.scala:108)\n\tat com.databricks.sql.transaction.tahoe.commands.CreateDeltaTableCommand.recordDeltaOperation(CreateDeltaTableCommand.scala:45)\n\tat com.databricks.sql.transaction.tahoe.commands.CreateDeltaTableCommand.run(CreateDeltaTableCommand.scala:93)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:70)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:68)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:86)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:150)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:138)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$5.apply(SparkPlan.scala:191)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:187)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:138)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:117)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:115)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:710)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:710)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withCustomExecutionEnv$1$$anonfun$apply$1.apply(SQLExecution.scala:112)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:217)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withCustomExecutionEnv$1.apply(SQLExecution.scala:98)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:835)\n\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:74)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:169)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:710)\n\tat org.apache.spark.sql.DataFrameWriter.createTable(DataFrameWriter.scala:508)\n\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:487)\n\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:430)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\n\n\nDuring handling of the above exception, another exception occurred:\n\n<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-891795827403174&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span>   <span class=\"ansi-blue-fg\">.</span>mode<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;append&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span>   <span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;delta&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">----&gt; 5</span><span class=\"ansi-red-fg\">   </span><span class=\"ansi-blue-fg\">.</span>saveAsTable<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">f&#39;{database_name}.{delta_table_name}&#39;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      6</span> )\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/readwriter.py</span> in <span class=\"ansi-cyan-fg\">saveAsTable</span><span class=\"ansi-blue-fg\">(self, name, format, mode, partitionBy, **options)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    776</span>         <span class=\"ansi-green-fg\">if</span> format <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">not</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    777</span>             self<span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>format<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 778</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>_jwrite<span class=\"ansi-blue-fg\">.</span>saveAsTable<span class=\"ansi-blue-fg\">(</span>name<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    779</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    780</span>     <span class=\"ansi-blue-fg\">@</span>since<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">1.4</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1255</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1256</span>         return_value = get_return_value(\n<span class=\"ansi-green-fg\">-&gt; 1257</span><span class=\"ansi-red-fg\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1258</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1259</span>         <span class=\"ansi-green-fg\">for</span> temp_arg <span class=\"ansi-green-fg\">in</span> temp_args<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     67</span>                                              e.java_exception.getStackTrace()))\n<span class=\"ansi-green-intense-fg ansi-bold\">     68</span>             <span class=\"ansi-green-fg\">if</span> s<span class=\"ansi-blue-fg\">.</span>startswith<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;org.apache.spark.sql.AnalysisException: &#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 69</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> AnalysisException<span class=\"ansi-blue-fg\">(</span>s<span class=\"ansi-blue-fg\">.</span>split<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;: &#39;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> stackTrace<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     70</span>             <span class=\"ansi-green-fg\">if</span> s<span class=\"ansi-blue-fg\">.</span>startswith<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;org.apache.spark.sql.catalyst.analysis&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     71</span>                 <span class=\"ansi-green-fg\">raise</span> AnalysisException<span class=\"ansi-blue-fg\">(</span>s<span class=\"ansi-blue-fg\">.</span>split<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;: &#39;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> stackTrace<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">AnalysisException</span>: &#34;Failed to merge fields &#39;stocks_left&#39; and &#39;stocks_left&#39;. Failed to merge incompatible data types LongType and DoubleType;;&#34;</div>"]}}],"execution_count":10},{"cell_type":"code","source":["sqlCmd = f\"SELECT * FROM {database_name}.{delta_table_name}\"\ndisplay(spark.sql(sqlCmd))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>product_id</th><th>product_name</th><th>row_flag</th><th>stocks_left</th></tr></thead><tbody><tr><td>1002</td><td>Apple iPhone 11</td><td>I</td><td>22</td></tr><tr><td>1002</td><td>Apple iPhone 11</td><td>I</td><td>22</td></tr><tr><td>1001</td><td>Apple Mac Book</td><td>I</td><td>11</td></tr><tr><td>1001</td><td>Apple Mac Book</td><td>I</td><td>11</td></tr><tr><td>1004</td><td>Dell Inspiron</td><td>I</td><td>44</td></tr><tr><td>1004</td><td>Dell Inspiron</td><td>I</td><td>44</td></tr><tr><td>1003</td><td>Redmi Note 4</td><td>I</td><td>33</td></tr><tr><td>1003</td><td>Redmi Note 4</td><td>I</td><td>33</td></tr></tbody></table></div>"]}}],"execution_count":11},{"cell_type":"code","source":["sqlCmd = f\"SELECT * FROM {database_name}.{parquet_table_name}\"\ndisplay(spark.sql(sqlCmd))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>product_id</th><th>product_name</th><th>row_flag</th><th>stocks_left</th></tr></thead><tbody><tr><td>1002</td><td>Apple iPhone 11</td><td>I</td><td>22</td></tr><tr><td>1002</td><td>Apple iPhone 11</td><td>I</td><td>22</td></tr><tr><td>1002</td><td>Apple iPhone 11</td><td>I</td><td>22</td></tr><tr><td>1002</td><td>Apple iPhone 11</td><td>I</td><td>22</td></tr><tr><td>1002</td><td>Apple iPhone 11</td><td>I</td><td>22</td></tr><tr><td>1001</td><td>Apple Mac Book</td><td>I</td><td>11</td></tr><tr><td>1001</td><td>Apple Mac Book</td><td>I</td><td>11</td></tr><tr><td>1001</td><td>Apple Mac Book</td><td>I</td><td>11</td></tr><tr><td>1001</td><td>Apple Mac Book</td><td>I</td><td>11</td></tr><tr><td>1004</td><td>Dell Inspiron</td><td>I</td><td>44</td></tr><tr><td>1004</td><td>Dell Inspiron</td><td>I</td><td>44</td></tr><tr><td>1004</td><td>Dell Inspiron</td><td>I</td><td>44</td></tr><tr><td>1004</td><td>Dell Inspiron</td><td>I</td><td>44</td></tr><tr><td>1004</td><td>Dell Inspiron</td><td>I</td><td>44</td></tr><tr><td>1003</td><td>Redmi Note 4</td><td>I</td><td>33</td></tr><tr><td>1003</td><td>Redmi Note 4</td><td>I</td><td>33</td></tr><tr><td>1003</td><td>Redmi Note 4</td><td>I</td><td>33</td></tr><tr><td>1003</td><td>Redmi Note 4</td><td>I</td><td>33</td></tr><tr><td>1003</td><td>Redmi Note 4</td><td>I</td><td>33</td></tr><tr><td>1001</td><td>Apple Mac Book</td><td>I</td><td>null</td></tr></tbody></table></div>"]}}],"execution_count":12},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["l = [(1001,'Apple Mac Book', 11, 'I', 'new_1'),(1002,'Apple iPhone 11', 22, 'I', 'new_2'),(1003,'Redmi Note 4', 33, 'I', 'new_3'),(1004, 'Dell Inspiron', 44, 'I', 'new_4')]\nrdd = sc.parallelize(l)\nschemaRdd = rdd.map(lambda x: Row(product_id=int(x[0]), product_name=x[1], stocks_left=int(x[2]), row_flag=x[3], new_col=x[4]))\nnew_col_product_df = spark.createDataFrame(schemaRdd)\ndisplay(new_col_product_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>new_col</th><th>product_id</th><th>product_name</th><th>row_flag</th><th>stocks_left</th></tr></thead><tbody><tr><td>new_1</td><td>1001</td><td>Apple Mac Book</td><td>I</td><td>11</td></tr><tr><td>new_2</td><td>1002</td><td>Apple iPhone 11</td><td>I</td><td>22</td></tr><tr><td>new_3</td><td>1003</td><td>Redmi Note 4</td><td>I</td><td>33</td></tr><tr><td>new_4</td><td>1004</td><td>Dell Inspiron</td><td>I</td><td>44</td></tr></tbody></table></div>"]}}],"execution_count":15},{"cell_type":"code","source":["new_col_product_df.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- new_col: string (nullable = true)\n-- product_id: long (nullable = true)\n-- product_name: string (nullable = true)\n-- row_flag: string (nullable = true)\n-- stocks_left: long (nullable = true)\n\n</div>"]}}],"execution_count":16},{"cell_type":"code","source":["(new_col_product_df\n  .repartition(2)\n  .write\n  .mode(\"append\")\n  .format(\"parquet\")\n  .saveAsTable(f'{database_name}.{parquet_table_name}')\n)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     62</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 63</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     64</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    327</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}.\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-fg\">--&gt; 328</span><span class=\"ansi-red-fg\">                     format(target_id, &#34;.&#34;, name), value)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    329</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-red-fg\">Py4JJavaError</span>: An error occurred while calling o2742.saveAsTable.\n: org.apache.spark.sql.AnalysisException: The column number of the existing table delta_demo.product_table_parquet(struct&lt;product_id:bigint,product_name:string,row_flag:string,stocks_left:bigint&gt;) doesn&#39;t match the data schema(struct&lt;new_col:string,product_id:bigint,product_name:string,row_flag:string,stocks_left:string&gt;);\n\tat org.apache.spark.sql.execution.datasources.PreprocessTableCreation$$anonfun$apply$2.applyOrElse(rules.scala:197)\n\tat org.apache.spark.sql.execution.datasources.PreprocessTableCreation$$anonfun$apply$2.applyOrElse(rules.scala:138)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsDown$1$$anonfun$2.apply(AnalysisHelper.scala:108)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsDown$1$$anonfun$2.apply(AnalysisHelper.scala:108)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:76)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsDown$1.apply(AnalysisHelper.scala:107)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsDown$1.apply(AnalysisHelper.scala:106)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsDown(AnalysisHelper.scala:106)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDown(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperators(AnalysisHelper.scala:73)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.execution.datasources.PreprocessTableCreation.apply(rules.scala:138)\n\tat org.apache.spark.sql.execution.datasources.PreprocessTableCreation.apply(rules.scala:134)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:112)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:109)\n\tat scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124)\n\tat scala.collection.immutable.List.foldLeft(List.scala:84)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:109)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:101)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:101)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:137)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:131)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:103)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$executeAndTrack$1.apply(RuleExecutor.scala:80)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$executeAndTrack$1.apply(RuleExecutor.scala:80)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:88)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:79)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:115)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:114)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:114)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$analyzed$1.apply(QueryExecution.scala:85)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$analyzed$1.apply(QueryExecution.scala:86)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$executePhase$1.apply(QueryExecution.scala:229)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:835)\n\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:228)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:83)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:83)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:75)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$withCachedData$1.apply(QueryExecution.scala:90)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$withCachedData$1.apply(QueryExecution.scala:89)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:835)\n\tat org.apache.spark.sql.execution.QueryExecution.withCachedData$lzycompute(QueryExecution.scala:89)\n\tat org.apache.spark.sql.execution.QueryExecution.withCachedData(QueryExecution.scala:89)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$optimizedPlan$1.apply(QueryExecution.scala:96)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$optimizedPlan$1.apply(QueryExecution.scala:96)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$executePhase$1.apply(QueryExecution.scala:229)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:835)\n\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:228)\n\tat org.apache.spark.sql.execution.QueryExecution.optimizedPlan$lzycompute(QueryExecution.scala:95)\n\tat org.apache.spark.sql.execution.QueryExecution.optimizedPlan(QueryExecution.scala:95)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$sparkPlan$1.apply(QueryExecution.scala:100)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$sparkPlan$1.apply(QueryExecution.scala:100)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$executePhase$1.apply(QueryExecution.scala:229)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:835)\n\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:228)\n\tat org.apache.spark.sql.execution.QueryExecution.sparkPlan$lzycompute(QueryExecution.scala:99)\n\tat org.apache.spark.sql.execution.QueryExecution.sparkPlan(QueryExecution.scala:99)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$executedPlan$1.apply(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$executedPlan$1.apply(QueryExecution.scala:106)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$executePhase$1.apply(QueryExecution.scala:229)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:835)\n\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:228)\n\tat org.apache.spark.sql.execution.QueryExecution.executedPlan$lzycompute(QueryExecution.scala:106)\n\tat org.apache.spark.sql.execution.QueryExecution.executedPlan(QueryExecution.scala:106)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withCustomExecutionEnv$1$$anonfun$apply$1.apply(SQLExecution.scala:106)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:217)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withCustomExecutionEnv$1.apply(SQLExecution.scala:98)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:835)\n\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:74)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:169)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:710)\n\tat org.apache.spark.sql.DataFrameWriter.createTable(DataFrameWriter.scala:508)\n\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:487)\n\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:430)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\n\n\nDuring handling of the above exception, another exception occurred:\n\n<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-891795827403183&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span>   <span class=\"ansi-blue-fg\">.</span>mode<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;append&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span>   <span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;parquet&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">----&gt; 5</span><span class=\"ansi-red-fg\">   </span><span class=\"ansi-blue-fg\">.</span>saveAsTable<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">f&#39;{database_name}.{parquet_table_name}&#39;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      6</span> )\n<span class=\"ansi-green-intense-fg ansi-bold\">      7</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/readwriter.py</span> in <span class=\"ansi-cyan-fg\">saveAsTable</span><span class=\"ansi-blue-fg\">(self, name, format, mode, partitionBy, **options)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    776</span>         <span class=\"ansi-green-fg\">if</span> format <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">not</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    777</span>             self<span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>format<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 778</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>_jwrite<span class=\"ansi-blue-fg\">.</span>saveAsTable<span class=\"ansi-blue-fg\">(</span>name<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    779</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    780</span>     <span class=\"ansi-blue-fg\">@</span>since<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">1.4</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1255</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1256</span>         return_value = get_return_value(\n<span class=\"ansi-green-fg\">-&gt; 1257</span><span class=\"ansi-red-fg\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1258</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1259</span>         <span class=\"ansi-green-fg\">for</span> temp_arg <span class=\"ansi-green-fg\">in</span> temp_args<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     67</span>                                              e.java_exception.getStackTrace()))\n<span class=\"ansi-green-intense-fg ansi-bold\">     68</span>             <span class=\"ansi-green-fg\">if</span> s<span class=\"ansi-blue-fg\">.</span>startswith<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;org.apache.spark.sql.AnalysisException: &#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 69</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> AnalysisException<span class=\"ansi-blue-fg\">(</span>s<span class=\"ansi-blue-fg\">.</span>split<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;: &#39;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> stackTrace<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     70</span>             <span class=\"ansi-green-fg\">if</span> s<span class=\"ansi-blue-fg\">.</span>startswith<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;org.apache.spark.sql.catalyst.analysis&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     71</span>                 <span class=\"ansi-green-fg\">raise</span> AnalysisException<span class=\"ansi-blue-fg\">(</span>s<span class=\"ansi-blue-fg\">.</span>split<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;: &#39;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> stackTrace<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">AnalysisException</span>: &#34;The column number of the existing table delta_demo.product_table_parquet(struct&lt;product_id:bigint,product_name:string,row_flag:string,stocks_left:bigint&gt;) doesn&#39;t match the data schema(struct&lt;new_col:string,product_id:bigint,product_name:string,row_flag:string,stocks_left:string&gt;);&#34;</div>"]}}],"execution_count":17},{"cell_type":"code","source":["(new_col_product_df\n  .repartition(2)\n  .write\n  .mode(\"append\")\n  .format(\"delta\")\n  .saveAsTable(f'{database_name}.{delta_table_name}')\n)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     62</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 63</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     64</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    327</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}.\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-fg\">--&gt; 328</span><span class=\"ansi-red-fg\">                     format(target_id, &#34;.&#34;, name), value)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    329</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-red-fg\">Py4JJavaError</span>: An error occurred while calling o3662.saveAsTable.\n: org.apache.spark.sql.AnalysisException: A schema mismatch detected when writing to the Delta table (Table ID: 59535559-84e1-46da-a566-06c753305e5a).\nTo enable schema migration, please set:\n&#39;.option(&#34;mergeSchema&#34;, &#34;true&#34;)&#39;.\n\nTable schema:\nroot\n-- product_id: long (nullable = true)\n-- product_name: string (nullable = true)\n-- row_flag: string (nullable = true)\n-- stocks_left: long (nullable = true)\n\n\nData schema:\nroot\n-- new_col: string (nullable = true)\n-- product_id: long (nullable = true)\n-- product_name: string (nullable = true)\n-- row_flag: string (nullable = true)\n-- stocks_left: long (nullable = true)\n\n         \nIf Table ACLs are enabled, these options will be ignored. Please use the ALTER TABLE\ncommand for changing the schema.\n        ;\n\tat com.databricks.sql.transaction.tahoe.MetadataMismatchErrorBuilder.finalizeAndThrow(DeltaErrors.scala:948)\n\tat com.databricks.sql.transaction.tahoe.schema.ImplicitMetadataOperation$class.updateMetadata(ImplicitMetadataOperation.scala:125)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDelta.updateMetadata(WriteIntoDelta.scala:50)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDelta.write(WriteIntoDelta.scala:91)\n\tat com.databricks.sql.transaction.tahoe.commands.CreateDeltaTableCommand$$anonfun$run$2.apply(CreateDeltaTableCommand.scala:119)\n\tat com.databricks.sql.transaction.tahoe.commands.CreateDeltaTableCommand$$anonfun$run$2.apply(CreateDeltaTableCommand.scala:93)\n\tat com.databricks.logging.UsageLogging$$anonfun$recordOperation$1.apply(UsageLogging.scala:428)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:238)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:233)\n\tat com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:18)\n\tat com.databricks.logging.UsageLogging$class.withAttributionTags(UsageLogging.scala:275)\n\tat com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:18)\n\tat com.databricks.logging.UsageLogging$class.recordOperation(UsageLogging.scala:409)\n\tat com.databricks.spark.util.PublicDBLogging.recordOperation(DatabricksSparkUsageLogger.scala:18)\n\tat com.databricks.spark.util.PublicDBLogging.recordOperation0(DatabricksSparkUsageLogger.scala:55)\n\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:98)\n\tat com.databricks.spark.util.UsageLogger$class.recordOperation(UsageLogger.scala:67)\n\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:67)\n\tat com.databricks.spark.util.UsageLogging$class.recordOperation(UsageLogger.scala:342)\n\tat com.databricks.sql.transaction.tahoe.commands.CreateDeltaTableCommand.recordOperation(CreateDeltaTableCommand.scala:45)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging$class.recordDeltaOperation(DeltaLogging.scala:108)\n\tat com.databricks.sql.transaction.tahoe.commands.CreateDeltaTableCommand.recordDeltaOperation(CreateDeltaTableCommand.scala:45)\n\tat com.databricks.sql.transaction.tahoe.commands.CreateDeltaTableCommand.run(CreateDeltaTableCommand.scala:93)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:70)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:68)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:86)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:150)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:138)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$5.apply(SparkPlan.scala:191)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:187)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:138)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:117)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:115)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:710)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:710)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withCustomExecutionEnv$1$$anonfun$apply$1.apply(SQLExecution.scala:112)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:217)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withCustomExecutionEnv$1.apply(SQLExecution.scala:98)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:835)\n\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:74)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:169)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:710)\n\tat org.apache.spark.sql.DataFrameWriter.createTable(DataFrameWriter.scala:508)\n\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:487)\n\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:430)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\n\n\nDuring handling of the above exception, another exception occurred:\n\n<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-891795827403184&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span>   <span class=\"ansi-blue-fg\">.</span>mode<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;append&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span>   <span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;delta&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">----&gt; 5</span><span class=\"ansi-red-fg\">   </span><span class=\"ansi-blue-fg\">.</span>saveAsTable<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">f&#39;{database_name}.{delta_table_name}&#39;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      6</span> )\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/readwriter.py</span> in <span class=\"ansi-cyan-fg\">saveAsTable</span><span class=\"ansi-blue-fg\">(self, name, format, mode, partitionBy, **options)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    776</span>         <span class=\"ansi-green-fg\">if</span> format <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">not</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    777</span>             self<span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>format<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 778</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>_jwrite<span class=\"ansi-blue-fg\">.</span>saveAsTable<span class=\"ansi-blue-fg\">(</span>name<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    779</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    780</span>     <span class=\"ansi-blue-fg\">@</span>since<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">1.4</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1255</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1256</span>         return_value = get_return_value(\n<span class=\"ansi-green-fg\">-&gt; 1257</span><span class=\"ansi-red-fg\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1258</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1259</span>         <span class=\"ansi-green-fg\">for</span> temp_arg <span class=\"ansi-green-fg\">in</span> temp_args<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     67</span>                                              e.java_exception.getStackTrace()))\n<span class=\"ansi-green-intense-fg ansi-bold\">     68</span>             <span class=\"ansi-green-fg\">if</span> s<span class=\"ansi-blue-fg\">.</span>startswith<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;org.apache.spark.sql.AnalysisException: &#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 69</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> AnalysisException<span class=\"ansi-blue-fg\">(</span>s<span class=\"ansi-blue-fg\">.</span>split<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;: &#39;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> stackTrace<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     70</span>             <span class=\"ansi-green-fg\">if</span> s<span class=\"ansi-blue-fg\">.</span>startswith<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;org.apache.spark.sql.catalyst.analysis&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     71</span>                 <span class=\"ansi-green-fg\">raise</span> AnalysisException<span class=\"ansi-blue-fg\">(</span>s<span class=\"ansi-blue-fg\">.</span>split<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;: &#39;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> stackTrace<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">AnalysisException</span>: &#39;A schema mismatch detected when writing to the Delta table (Table ID: 59535559-84e1-46da-a566-06c753305e5a).\\nTo enable schema migration, please set:\\n\\&#39;.option(&#34;mergeSchema&#34;, &#34;true&#34;)\\&#39;.\\n\\nTable schema:\\nroot\\n-- product_id: long (nullable = true)\\n-- product_name: string (nullable = true)\\n-- row_flag: string (nullable = true)\\n-- stocks_left: long (nullable = true)\\n\\n\\nData schema:\\nroot\\n-- new_col: string (nullable = true)\\n-- product_id: long (nullable = true)\\n-- product_name: string (nullable = true)\\n-- row_flag: string (nullable = true)\\n-- stocks_left: long (nullable = true)\\n\\n         \\nIf Table ACLs are enabled, these options will be ignored. Please use the ALTER TABLE\\ncommand for changing the schema.\\n        ;&#39;</div>"]}}],"execution_count":18},{"cell_type":"code","source":["(new_col_product_df\n  .repartition(2)\n  .write\n  .mode(\"append\")\n  .option(\"mergeSchema\", True)\n  .format(\"delta\")\n  .saveAsTable(f'{database_name}.{delta_table_name}')\n)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":19},{"cell_type":"code","source":["sqlCmd = f\"SELECT * FROM {database_name}.{parquet_table_name}\"\ndisplay(spark.sql(sqlCmd))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>product_id</th><th>product_name</th><th>row_flag</th><th>stocks_left</th></tr></thead><tbody><tr><td>1002</td><td>Apple iPhone 11</td><td>I</td><td>22</td></tr><tr><td>1002</td><td>Apple iPhone 11</td><td>I</td><td>22</td></tr><tr><td>1002</td><td>Apple iPhone 11</td><td>I</td><td>22</td></tr><tr><td>1002</td><td>Apple iPhone 11</td><td>I</td><td>22</td></tr><tr><td>1002</td><td>Apple iPhone 11</td><td>I</td><td>22</td></tr><tr><td>1001</td><td>Apple Mac Book</td><td>I</td><td>11</td></tr><tr><td>1001</td><td>Apple Mac Book</td><td>I</td><td>11</td></tr><tr><td>1001</td><td>Apple Mac Book</td><td>I</td><td>11</td></tr><tr><td>1001</td><td>Apple Mac Book</td><td>I</td><td>11</td></tr><tr><td>1004</td><td>Dell Inspiron</td><td>I</td><td>44</td></tr><tr><td>1004</td><td>Dell Inspiron</td><td>I</td><td>44</td></tr><tr><td>1004</td><td>Dell Inspiron</td><td>I</td><td>44</td></tr><tr><td>1004</td><td>Dell Inspiron</td><td>I</td><td>44</td></tr><tr><td>1004</td><td>Dell Inspiron</td><td>I</td><td>44</td></tr><tr><td>1003</td><td>Redmi Note 4</td><td>I</td><td>33</td></tr><tr><td>1003</td><td>Redmi Note 4</td><td>I</td><td>33</td></tr><tr><td>1003</td><td>Redmi Note 4</td><td>I</td><td>33</td></tr><tr><td>1003</td><td>Redmi Note 4</td><td>I</td><td>33</td></tr><tr><td>1003</td><td>Redmi Note 4</td><td>I</td><td>33</td></tr><tr><td>1001</td><td>Apple Mac Book</td><td>I</td><td>null</td></tr></tbody></table></div>"]}}],"execution_count":20},{"cell_type":"code","source":["sqlCmd = f\"SELECT * FROM {database_name}.{delta_table_name}\"\ndisplay(spark.sql(sqlCmd))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>product_id</th><th>product_name</th><th>row_flag</th><th>stocks_left</th><th>new_col</th></tr></thead><tbody><tr><td>1002</td><td>Apple iPhone 11</td><td>I</td><td>22</td><td>new_2</td></tr><tr><td>1001</td><td>Apple Mac Book</td><td>I</td><td>11</td><td>new_1</td></tr><tr><td>1004</td><td>Dell Inspiron</td><td>I</td><td>44</td><td>new_4</td></tr><tr><td>1003</td><td>Redmi Note 4</td><td>I</td><td>33</td><td>new_3</td></tr><tr><td>1002</td><td>Apple iPhone 11</td><td>I</td><td>22</td><td>null</td></tr><tr><td>1001</td><td>Apple Mac Book</td><td>I</td><td>11</td><td>null</td></tr><tr><td>1004</td><td>Dell Inspiron</td><td>I</td><td>44</td><td>null</td></tr><tr><td>1003</td><td>Redmi Note 4</td><td>I</td><td>33</td><td>null</td></tr></tbody></table></div>"]}}],"execution_count":21},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":["### Changing a column’s type or name or dropping a column requires rewriting the table. To do this, use the overwriteSchema option:"],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":["# CDC USE CASE - DML/DDL"],"metadata":{}},{"cell_type":"code","source":["l = [(1001,'Apple Mac Book', 110, 'U', 'new_1'),(1002,'Apple iPhone 11', 2, 'U', 'new_2'),(1003,'Redmi Note 4', 3, 'U', 'new_3'),(1004, 'Dell Inspiron', 0, 'D', 'new_4')]\nrdd = sc.parallelize(l)\nschemaRdd = rdd.map(lambda x: Row(product_id=int(x[0]), product_name=x[1], stocks_left=int(x[2]), row_flag=x[3], new_col=x[4]))\nmerge_product_df = spark.createDataFrame(schemaRdd)\ndisplay(merge_product_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>new_col</th><th>product_id</th><th>product_name</th><th>row_flag</th><th>stocks_left</th></tr></thead><tbody><tr><td>new_1</td><td>1001</td><td>Apple Mac Book</td><td>U</td><td>110</td></tr><tr><td>new_2</td><td>1002</td><td>Apple iPhone 11</td><td>U</td><td>2</td></tr><tr><td>new_3</td><td>1003</td><td>Redmi Note 4</td><td>U</td><td>3</td></tr><tr><td>new_4</td><td>1004</td><td>Dell Inspiron</td><td>D</td><td>0</td></tr></tbody></table></div>"]}}],"execution_count":29},{"cell_type":"code","source":["merge_product_df.createOrReplaceTempView('source_table')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":30},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["spark.sql(\"\"\"\n          MERGE INTO delta_demo.product_table_delta target_table\n          USING source_table\n          ON source_table.product_id = target_table.product_id\n          WHEN MATCHED AND source_table.row_flag = 'U'\n          THEN\n          UPDATE SET *\n          WHEN MATCHED AND source_table.row_flag = 'D'\n          THEN DELETE\n          WHEN NOT MATCHED and source_table.row_flag = 'I'\n          THEN INSERT *\n          \"\"\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[24]: DataFrame[]</div>"]}}],"execution_count":32},{"cell_type":"code","source":["sqlCmd = f\"SELECT * FROM {database_name}.{delta_table_name}\"\ndisplay(spark.sql(sqlCmd))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>product_id</th><th>product_name</th><th>row_flag</th><th>stocks_left</th><th>new_col</th></tr></thead><tbody><tr><td>1002</td><td>Apple iPhone 11</td><td>U</td><td>2</td><td>new_2</td></tr><tr><td>1002</td><td>Apple iPhone 11</td><td>U</td><td>2</td><td>new_2</td></tr><tr><td>1001</td><td>Apple Mac Book</td><td>U</td><td>110</td><td>new_1</td></tr><tr><td>1001</td><td>Apple Mac Book</td><td>U</td><td>110</td><td>new_1</td></tr><tr><td>1003</td><td>Redmi Note 4</td><td>U</td><td>3</td><td>new_3</td></tr><tr><td>1003</td><td>Redmi Note 4</td><td>U</td><td>3</td><td>new_3</td></tr></tbody></table></div>"]}}],"execution_count":33},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"markdown","source":["# SHOW I/U/D counts, this features was not there previously. If possible also show the slack channel screenshot"],"metadata":{}},{"cell_type":"code","source":["%sql\n\ndescribe history delta_demo.product_table_delta\n\n-- Table history is retained for 30 days"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>version</th><th>timestamp</th><th>userId</th><th>userName</th><th>operation</th><th>operationParameters</th><th>job</th><th>notebook</th><th>clusterId</th><th>readVersion</th><th>isolationLevel</th><th>isBlindAppend</th><th>operationMetrics</th></tr></thead><tbody><tr><td>7</td><td>2020-06-28T10:52:13.000+0000</td><td>1583409609571278</td><td>techieeisland@gmail.com</td><td>MERGE</td><td>Map(predicate -> (source_table.`product_id` = target_table.`product_id`), updatePredicate -> (source_table.`row_flag` = 'U'), deletePredicate -> (source_table.`row_flag` = 'D'), insertPredicate -> (source_table.`row_flag` = 'I'))</td><td>null</td><td>List(891795827403111)</td><td>0628-102648-pick544</td><td>6</td><td>WriteSerializable</td><td>false</td><td>Map(numTargetRowsCopied -> 0, numTargetRowsDeleted -> 2, numFiles -> 4, numTargetFilesAfterSkipping -> 10, numTargetFilesAdded -> 4, numTargetRowsInserted -> 0, numTargetRowsUpdated -> 6, numOutputRows -> 6, numParts -> 0, numOutputBytes -> 5583, numSourceRows -> 4, numTargetFilesRemoved -> 8, numTargetFilesBeforeSkipping -> 10)</td></tr><tr><td>6</td><td>2020-06-28T10:41:40.000+0000</td><td>1583409609571278</td><td>techieeisland@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, partitionBy -> [])</td><td>null</td><td>List(891795827403111)</td><td>0628-102648-pick544</td><td>5</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 5, numOutputBytes -> 6618, numOutputRows -> 4, numParts -> 0)</td></tr><tr><td>5</td><td>2020-06-28T10:38:26.000+0000</td><td>1583409609571278</td><td>techieeisland@gmail.com</td><td>WRITE</td><td>Map(mode -> Overwrite, partitionBy -> [])</td><td>null</td><td>List(891795827403111)</td><td>0628-102648-pick544</td><td>4</td><td>WriteSerializable</td><td>false</td><td>Map(numFiles -> 5, numOutputBytes -> 5602, numOutputRows -> 4, numParts -> 0)</td></tr><tr><td>4</td><td>2020-06-28T10:36:48.000+0000</td><td>1583409609571278</td><td>techieeisland@gmail.com</td><td>WRITE</td><td>Map(mode -> Overwrite, partitionBy -> [])</td><td>null</td><td>List(891795827403111)</td><td>0628-102648-pick544</td><td>3</td><td>WriteSerializable</td><td>false</td><td>Map(numFiles -> 5, numOutputBytes -> 5602, numOutputRows -> 4, numParts -> 0)</td></tr><tr><td>3</td><td>2020-06-28T08:17:46.000+0000</td><td>1583409609571278</td><td>techieeisland@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, partitionBy -> [])</td><td>null</td><td>List(891795827403111)</td><td>0628-070251-hove428</td><td>2</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 5, numOutputBytes -> 6618, numOutputRows -> 4, numParts -> 0)</td></tr><tr><td>2</td><td>2020-06-28T08:00:00.000+0000</td><td>1583409609571278</td><td>techieeisland@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, partitionBy -> [])</td><td>null</td><td>List(891795827403111)</td><td>0628-070251-hove428</td><td>1</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 5, numOutputBytes -> 5602, numOutputRows -> 4, numParts -> 0)</td></tr><tr><td>1</td><td>2020-06-28T07:44:11.000+0000</td><td>1583409609571278</td><td>techieeisland@gmail.com</td><td>WRITE</td><td>Map(mode -> Overwrite, partitionBy -> [])</td><td>null</td><td>List(891795827403111)</td><td>0628-070251-hove428</td><td>0</td><td>WriteSerializable</td><td>false</td><td>Map(numFiles -> 5, numOutputBytes -> 5602, numOutputRows -> 4, numParts -> 0)</td></tr><tr><td>0</td><td>2020-06-28T07:40:12.000+0000</td><td>1583409609571278</td><td>techieeisland@gmail.com</td><td>WRITE</td><td>Map(mode -> Overwrite, partitionBy -> [])</td><td>null</td><td>List(891795827403111)</td><td>0628-070251-hove428</td><td>null</td><td>WriteSerializable</td><td>false</td><td>Map(numFiles -> 5, numOutputBytes -> 5602, numOutputRows -> 4, numParts -> 0)</td></tr></tbody></table></div>"]}}],"execution_count":36},{"cell_type":"code","source":["%sql\n\nselect operationMetrics.numTargetRowsInserted, operationMetrics.numTargetRowsUpdated, operationMetrics.numTargetRowsDeleted from (describe history delta_demo.product_table_delta limit 1)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>numTargetRowsInserted</th><th>numTargetRowsUpdated</th><th>numTargetRowsDeleted</th></tr></thead><tbody><tr><td>0</td><td>6</td><td>2</td></tr></tbody></table></div>"]}}],"execution_count":37},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"markdown","source":["# TIME TRAVEL"],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"code","source":["%sql\n\nselect * from delta_demo.product_table_delta version as of 1"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>product_id</th><th>product_name</th><th>row_flag</th><th>stocks_left</th></tr></thead><tbody><tr><td>1002</td><td>Apple iPhone 11</td><td>I</td><td>22</td></tr><tr><td>1001</td><td>Apple Mac Book</td><td>I</td><td>11</td></tr><tr><td>1004</td><td>Dell Inspiron</td><td>I</td><td>44</td></tr><tr><td>1003</td><td>Redmi Note 4</td><td>I</td><td>33</td></tr></tbody></table></div>"]}}],"execution_count":41},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"markdown","source":["# SHOW TRANSACTIONAL LOG FILES"],"metadata":{}},{"cell_type":"code","source":["%fs\n\nls dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/.s3-optimization-0</td><td>.s3-optimization-0</td><td>0</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/.s3-optimization-1</td><td>.s3-optimization-1</td><td>0</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/.s3-optimization-2</td><td>.s3-optimization-2</td><td>0</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000000.crc</td><td>00000000000000000000.crc</td><td>89</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000000.json</td><td>00000000000000000000.json</td><td>3287</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000001.crc</td><td>00000000000000000001.crc</td><td>89</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000001.json</td><td>00000000000000000001.json</td><td>3414</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000002.crc</td><td>00000000000000000002.crc</td><td>91</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000002.json</td><td>00000000000000000002.json</td><td>2700</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000003.crc</td><td>00000000000000000003.crc</td><td>91</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000003.json</td><td>00000000000000000003.json</td><td>3551</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000004.crc</td><td>00000000000000000004.crc</td><td>89</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000004.json</td><td>00000000000000000004.json</td><td>4834</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000005.crc</td><td>00000000000000000005.crc</td><td>89</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000005.json</td><td>00000000000000000005.json</td><td>3956</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000006.crc</td><td>00000000000000000006.crc</td><td>91</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000006.json</td><td>00000000000000000006.json</td><td>3551</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000007.crc</td><td>00000000000000000007.crc</td><td>89</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000007.json</td><td>00000000000000000007.json</td><td>3950</td></tr></tbody></table></div>"]}}],"execution_count":45},{"cell_type":"code","source":["%fs\n\nls dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/.s3-optimization-0</td><td>.s3-optimization-0</td><td>0</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/.s3-optimization-1</td><td>.s3-optimization-1</td><td>0</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/.s3-optimization-2</td><td>.s3-optimization-2</td><td>0</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000000.crc</td><td>00000000000000000000.crc</td><td>89</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000000.json</td><td>00000000000000000000.json</td><td>3287</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000001.crc</td><td>00000000000000000001.crc</td><td>89</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000001.json</td><td>00000000000000000001.json</td><td>3414</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000002.crc</td><td>00000000000000000002.crc</td><td>91</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000002.json</td><td>00000000000000000002.json</td><td>2700</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000003.crc</td><td>00000000000000000003.crc</td><td>91</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000003.json</td><td>00000000000000000003.json</td><td>3551</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000004.crc</td><td>00000000000000000004.crc</td><td>89</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000004.json</td><td>00000000000000000004.json</td><td>4834</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000005.crc</td><td>00000000000000000005.crc</td><td>89</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000005.json</td><td>00000000000000000005.json</td><td>3956</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000006.crc</td><td>00000000000000000006.crc</td><td>91</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000006.json</td><td>00000000000000000006.json</td><td>3551</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000007.crc</td><td>00000000000000000007.crc</td><td>89</td></tr><tr><td>dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000007.json</td><td>00000000000000000007.json</td><td>3950</td></tr></tbody></table></div>"]}}],"execution_count":46},{"cell_type":"code","source":["%fs\n\nhead dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000006.json"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">{&quot;commitInfo&quot;:{&quot;timestamp&quot;:1593340899589,&quot;userId&quot;:&quot;1583409609571278&quot;,&quot;userName&quot;:&quot;techieeisland@gmail.com&quot;,&quot;operation&quot;:&quot;WRITE&quot;,&quot;operationParameters&quot;:{&quot;mode&quot;:&quot;Append&quot;,&quot;partitionBy&quot;:&quot;[]&quot;},&quot;notebook&quot;:{&quot;notebookId&quot;:&quot;891795827403111&quot;},&quot;clusterId&quot;:&quot;0628-102648-pick544&quot;,&quot;readVersion&quot;:5,&quot;isolationLevel&quot;:&quot;WriteSerializable&quot;,&quot;isBlindAppend&quot;:true,&quot;operationMetrics&quot;:{&quot;numFiles&quot;:&quot;5&quot;,&quot;numOutputBytes&quot;:&quot;6618&quot;,&quot;numOutputRows&quot;:&quot;4&quot;,&quot;numParts&quot;:&quot;0&quot;}}}\n{&quot;metaData&quot;:{&quot;id&quot;:&quot;59535559-84e1-46da-a566-06c753305e5a&quot;,&quot;format&quot;:{&quot;provider&quot;:&quot;parquet&quot;,&quot;options&quot;:{}},&quot;schemaString&quot;:&quot;{\\&quot;type\\&quot;:\\&quot;struct\\&quot;,\\&quot;fields\\&quot;:[{\\&quot;name\\&quot;:\\&quot;product_id\\&quot;,\\&quot;type\\&quot;:\\&quot;long\\&quot;,\\&quot;nullable\\&quot;:true,\\&quot;metadata\\&quot;:{}},{\\&quot;name\\&quot;:\\&quot;product_name\\&quot;,\\&quot;type\\&quot;:\\&quot;string\\&quot;,\\&quot;nullable\\&quot;:true,\\&quot;metadata\\&quot;:{}},{\\&quot;name\\&quot;:\\&quot;row_flag\\&quot;,\\&quot;type\\&quot;:\\&quot;string\\&quot;,\\&quot;nullable\\&quot;:true,\\&quot;metadata\\&quot;:{}},{\\&quot;name\\&quot;:\\&quot;stocks_left\\&quot;,\\&quot;type\\&quot;:\\&quot;long\\&quot;,\\&quot;nullable\\&quot;:true,\\&quot;metadata\\&quot;:{}},{\\&quot;name\\&quot;:\\&quot;new_col\\&quot;,\\&quot;type\\&quot;:\\&quot;string\\&quot;,\\&quot;nullable\\&quot;:true,\\&quot;metadata\\&quot;:{}}]}&quot;,&quot;partitionColumns&quot;:[],&quot;configuration&quot;:{},&quot;createdTime&quot;:1593330009451}}\n{&quot;add&quot;:{&quot;path&quot;:&quot;part-00000-1baa5b2e-f525-45d6-9ea4-ae79ba1bdceb-c000.snappy.parquet&quot;,&quot;partitionValues&quot;:{},&quot;size&quot;:645,&quot;modificationTime&quot;:1593340900000,&quot;dataChange&quot;:true,&quot;stats&quot;:&quot;{\\&quot;numRecords\\&quot;:0,\\&quot;minValues\\&quot;:{},\\&quot;maxValues\\&quot;:{},\\&quot;nullCount\\&quot;:{}}&quot;}}\n{&quot;add&quot;:{&quot;path&quot;:&quot;part-00001-d26756df-406f-4db0-a66f-ab5ccf574d96-c000.snappy.parquet&quot;,&quot;partitionValues&quot;:{},&quot;size&quot;:1498,&quot;modificationTime&quot;:1593340900000,&quot;dataChange&quot;:true,&quot;stats&quot;:&quot;{\\&quot;numRecords\\&quot;:1,\\&quot;minValues\\&quot;:{\\&quot;new_col\\&quot;:\\&quot;new_1\\&quot;,\\&quot;product_id\\&quot;:1001,\\&quot;product_name\\&quot;:\\&quot;Apple Mac Book\\&quot;,\\&quot;row_flag\\&quot;:\\&quot;I\\&quot;,\\&quot;stocks_left\\&quot;:11},\\&quot;maxValues\\&quot;:{\\&quot;new_col\\&quot;:\\&quot;new_1\\&quot;,\\&quot;product_id\\&quot;:1001,\\&quot;product_name\\&quot;:\\&quot;Apple Mac Book\\&quot;,\\&quot;row_flag\\&quot;:\\&quot;I\\&quot;,\\&quot;stocks_left\\&quot;:11},\\&quot;nullCount\\&quot;:{\\&quot;new_col\\&quot;:0,\\&quot;product_id\\&quot;:0,\\&quot;product_name\\&quot;:0,\\&quot;row_flag\\&quot;:0,\\&quot;stocks_left\\&quot;:0}}&quot;}}\n{&quot;add&quot;:{&quot;path&quot;:&quot;part-00003-a9cd7ebe-f8b6-4f0c-9344-997cab24eb3b-c000.snappy.parquet&quot;,&quot;partitionValues&quot;:{},&quot;size&quot;:1507,&quot;modificationTime&quot;:1593340900000,&quot;dataChange&quot;:true,&quot;stats&quot;:&quot;{\\&quot;numRecords\\&quot;:1,\\&quot;minValues\\&quot;:{\\&quot;new_col\\&quot;:\\&quot;new_2\\&quot;,\\&quot;product_id\\&quot;:1002,\\&quot;product_name\\&quot;:\\&quot;Apple iPhone 11\\&quot;,\\&quot;row_flag\\&quot;:\\&quot;I\\&quot;,\\&quot;stocks_left\\&quot;:22},\\&quot;maxValues\\&quot;:{\\&quot;new_col\\&quot;:\\&quot;new_2\\&quot;,\\&quot;product_id\\&quot;:1002,\\&quot;product_name\\&quot;:\\&quot;Apple iPhone 11\\&quot;,\\&quot;row_flag\\&quot;:\\&quot;I\\&quot;,\\&quot;stocks_left\\&quot;:22},\\&quot;nullCount\\&quot;:{\\&quot;new_col\\&quot;:0,\\&quot;product_id\\&quot;:0,\\&quot;product_name\\&quot;:0,\\&quot;row_flag\\&quot;:0,\\&quot;stocks_left\\&quot;:0}}&quot;}}\n{&quot;add&quot;:{&quot;path&quot;:&quot;part-00005-db28f365-bae8-43c1-89ba-85bf77fc7932-c000.snappy.parquet&quot;,&quot;partitionValues&quot;:{},&quot;size&quot;:1480,&quot;modificationTime&quot;:1593340900000,&quot;dataChange&quot;:true,&quot;stats&quot;:&quot;{\\&quot;numRecords\\&quot;:1,\\&quot;minValues\\&quot;:{\\&quot;new_col\\&quot;:\\&quot;new_3\\&quot;,\\&quot;product_id\\&quot;:1003,\\&quot;product_name\\&quot;:\\&quot;Redmi Note 4\\&quot;,\\&quot;row_flag\\&quot;:\\&quot;I\\&quot;,\\&quot;stocks_left\\&quot;:33},\\&quot;maxValues\\&quot;:{\\&quot;new_col\\&quot;:\\&quot;new_3\\&quot;,\\&quot;product_id\\&quot;:1003,\\&quot;product_name\\&quot;:\\&quot;Redmi Note 4\\&quot;,\\&quot;row_flag\\&quot;:\\&quot;I\\&quot;,\\&quot;stocks_left\\&quot;:33},\\&quot;nullCount\\&quot;:{\\&quot;new_col\\&quot;:0,\\&quot;product_id\\&quot;:0,\\&quot;product_name\\&quot;:0,\\&quot;row_flag\\&quot;:0,\\&quot;stocks_left\\&quot;:0}}&quot;}}\n{&quot;add&quot;:{&quot;path&quot;:&quot;part-00007-7ad2390f-b48f-422c-96e6-728bbc893028-c000.snappy.parquet&quot;,&quot;partitionValues&quot;:{},&quot;size&quot;:1489,&quot;modificationTime&quot;:1593340900000,&quot;dataChange&quot;:true,&quot;stats&quot;:&quot;{\\&quot;numRecords\\&quot;:1,\\&quot;minValues\\&quot;:{\\&quot;new_col\\&quot;:\\&quot;new_4\\&quot;,\\&quot;product_id\\&quot;:1004,\\&quot;product_name\\&quot;:\\&quot;Dell Inspiron\\&quot;,\\&quot;row_flag\\&quot;:\\&quot;I\\&quot;,\\&quot;stocks_left\\&quot;:44},\\&quot;maxValues\\&quot;:{\\&quot;new_col\\&quot;:\\&quot;new_4\\&quot;,\\&quot;product_id\\&quot;:1004,\\&quot;product_name\\&quot;:\\&quot;Dell Inspiron\\&quot;,\\&quot;row_flag\\&quot;:\\&quot;I\\&quot;,\\&quot;stocks_left\\&quot;:44},\\&quot;nullCount\\&quot;:{\\&quot;new_col\\&quot;:0,\\&quot;product_id\\&quot;:0,\\&quot;product_name\\&quot;:0,\\&quot;row_flag\\&quot;:0,\\&quot;stocks_left\\&quot;:0}}&quot;}}\n\n</div>"]}}],"execution_count":47},{"cell_type":"code","source":["display(spark.read.json(\"dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000006.json\"))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>add</th><th>commitInfo</th><th>metaData</th></tr></thead><tbody><tr><td>null</td><td>List(0628-102648-pick544, true, WriteSerializable, List(891795827403111), WRITE, List(5, 6618, 4, 0), List(Append, []), 5, 1593340899589, 1583409609571278, techieeisland@gmail.com)</td><td>null</td></tr><tr><td>null</td><td>null</td><td>List(1593330009451, List(parquet), 59535559-84e1-46da-a566-06c753305e5a, List(), {\"type\":\"struct\",\"fields\":[{\"name\":\"product_id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"product_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"row_flag\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"stocks_left\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"new_col\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]})</td></tr><tr><td>List(true, 1593340900000, part-00000-1baa5b2e-f525-45d6-9ea4-ae79ba1bdceb-c000.snappy.parquet, 645, {\"numRecords\":0,\"minValues\":{},\"maxValues\":{},\"nullCount\":{}})</td><td>null</td><td>null</td></tr><tr><td>List(true, 1593340900000, part-00001-d26756df-406f-4db0-a66f-ab5ccf574d96-c000.snappy.parquet, 1498, {\"numRecords\":1,\"minValues\":{\"new_col\":\"new_1\",\"product_id\":1001,\"product_name\":\"Apple Mac Book\",\"row_flag\":\"I\",\"stocks_left\":11},\"maxValues\":{\"new_col\":\"new_1\",\"product_id\":1001,\"product_name\":\"Apple Mac Book\",\"row_flag\":\"I\",\"stocks_left\":11},\"nullCount\":{\"new_col\":0,\"product_id\":0,\"product_name\":0,\"row_flag\":0,\"stocks_left\":0}})</td><td>null</td><td>null</td></tr><tr><td>List(true, 1593340900000, part-00003-a9cd7ebe-f8b6-4f0c-9344-997cab24eb3b-c000.snappy.parquet, 1507, {\"numRecords\":1,\"minValues\":{\"new_col\":\"new_2\",\"product_id\":1002,\"product_name\":\"Apple iPhone 11\",\"row_flag\":\"I\",\"stocks_left\":22},\"maxValues\":{\"new_col\":\"new_2\",\"product_id\":1002,\"product_name\":\"Apple iPhone 11\",\"row_flag\":\"I\",\"stocks_left\":22},\"nullCount\":{\"new_col\":0,\"product_id\":0,\"product_name\":0,\"row_flag\":0,\"stocks_left\":0}})</td><td>null</td><td>null</td></tr><tr><td>List(true, 1593340900000, part-00005-db28f365-bae8-43c1-89ba-85bf77fc7932-c000.snappy.parquet, 1480, {\"numRecords\":1,\"minValues\":{\"new_col\":\"new_3\",\"product_id\":1003,\"product_name\":\"Redmi Note 4\",\"row_flag\":\"I\",\"stocks_left\":33},\"maxValues\":{\"new_col\":\"new_3\",\"product_id\":1003,\"product_name\":\"Redmi Note 4\",\"row_flag\":\"I\",\"stocks_left\":33},\"nullCount\":{\"new_col\":0,\"product_id\":0,\"product_name\":0,\"row_flag\":0,\"stocks_left\":0}})</td><td>null</td><td>null</td></tr><tr><td>List(true, 1593340900000, part-00007-7ad2390f-b48f-422c-96e6-728bbc893028-c000.snappy.parquet, 1489, {\"numRecords\":1,\"minValues\":{\"new_col\":\"new_4\",\"product_id\":1004,\"product_name\":\"Dell Inspiron\",\"row_flag\":\"I\",\"stocks_left\":44},\"maxValues\":{\"new_col\":\"new_4\",\"product_id\":1004,\"product_name\":\"Dell Inspiron\",\"row_flag\":\"I\",\"stocks_left\":44},\"nullCount\":{\"new_col\":0,\"product_id\":0,\"product_name\":0,\"row_flag\":0,\"stocks_left\":0}})</td><td>null</td><td>null</td></tr></tbody></table></div>"]}}],"execution_count":48},{"cell_type":"code","source":["display(spark.read.json(\"dbfs:/user/hive/warehouse/delta_demo.db/product_table_delta/_delta_log/00000000000000000007.json\"))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>add</th><th>commitInfo</th><th>remove</th></tr></thead><tbody><tr><td>null</td><td>List(0628-102648-pick544, false, WriteSerializable, List(891795827403111), MERGE, List(4, 5583, 6, 0, 4, 4, 10, 10, 8, 0, 2, 0, 6), List((source_table.`row_flag` = 'D'), (source_table.`row_flag` = 'I'), (source_table.`product_id` = target_table.`product_id`), (source_table.`row_flag` = 'U')), 6, 1593341532506, 1583409609571278, techieeisland@gmail.com)</td><td>null</td></tr><tr><td>null</td><td>null</td><td>List(true, 1593341532454, part-00005-db28f365-bae8-43c1-89ba-85bf77fc7932-c000.snappy.parquet)</td></tr><tr><td>null</td><td>null</td><td>List(true, 1593341532502, part-00007-7ad2390f-b48f-422c-96e6-728bbc893028-c000.snappy.parquet)</td></tr><tr><td>null</td><td>null</td><td>List(true, 1593341532502, part-00001-d26756df-406f-4db0-a66f-ab5ccf574d96-c000.snappy.parquet)</td></tr><tr><td>null</td><td>null</td><td>List(true, 1593341532502, part-00003-f5307a9d-8be6-42d9-a9af-0b276c81e1d0-c000.snappy.parquet)</td></tr><tr><td>null</td><td>null</td><td>List(true, 1593341532502, part-00007-88bcdf6d-cb6b-4013-adaf-d63acc344dc8-c000.snappy.parquet)</td></tr><tr><td>null</td><td>null</td><td>List(true, 1593341532502, part-00003-a9cd7ebe-f8b6-4f0c-9344-997cab24eb3b-c000.snappy.parquet)</td></tr><tr><td>null</td><td>null</td><td>List(true, 1593341532502, part-00005-8b1e9299-6d7d-4e81-8650-d7b3b6d72626-c000.snappy.parquet)</td></tr><tr><td>null</td><td>null</td><td>List(true, 1593341532502, part-00001-60eb97be-368d-4dca-9643-191e93e04c93-c000.snappy.parquet)</td></tr><tr><td>List(true, 1593341529000, part-00000-dabb379d-646b-416d-b4f7-e2840c0a096b-c000.snappy.parquet, 645, {\"numRecords\":0,\"minValues\":{},\"maxValues\":{},\"nullCount\":{}})</td><td>null</td><td>null</td></tr><tr><td>List(true, 1593341529000, part-00022-14f63a46-593d-44e1-a01c-6ce406da5dcf-c000.snappy.parquet, 1658, {\"numRecords\":2,\"minValues\":{\"product_id\":1002,\"product_name\":\"Apple iPhone 11\",\"row_flag\":\"U\",\"stocks_left\":2,\"new_col\":\"new_2\"},\"maxValues\":{\"product_id\":1002,\"product_name\":\"Apple iPhone 11\",\"row_flag\":\"U\",\"stocks_left\":2,\"new_col\":\"new_2\"},\"nullCount\":{\"product_id\":0,\"product_name\":0,\"row_flag\":0,\"stocks_left\":0,\"new_col\":0}})</td><td>null</td><td>null</td></tr><tr><td>List(true, 1593341531000, part-00124-f7b91802-abdf-4fc7-8af2-1d94b6c0f4f8-c000.snappy.parquet, 1649, {\"numRecords\":2,\"minValues\":{\"product_id\":1001,\"product_name\":\"Apple Mac Book\",\"row_flag\":\"U\",\"stocks_left\":110,\"new_col\":\"new_1\"},\"maxValues\":{\"product_id\":1001,\"product_name\":\"Apple Mac Book\",\"row_flag\":\"U\",\"stocks_left\":110,\"new_col\":\"new_1\"},\"nullCount\":{\"product_id\":0,\"product_name\":0,\"row_flag\":0,\"stocks_left\":0,\"new_col\":0}})</td><td>null</td><td>null</td></tr><tr><td>List(true, 1593341533000, part-00189-89fc3a41-c31e-461f-8980-4c11bef0bcf3-c000.snappy.parquet, 1632, {\"numRecords\":2,\"minValues\":{\"product_id\":1003,\"product_name\":\"Redmi Note 4\",\"row_flag\":\"U\",\"stocks_left\":3,\"new_col\":\"new_3\"},\"maxValues\":{\"product_id\":1003,\"product_name\":\"Redmi Note 4\",\"row_flag\":\"U\",\"stocks_left\":3,\"new_col\":\"new_3\"},\"nullCount\":{\"product_id\":0,\"product_name\":0,\"row_flag\":0,\"stocks_left\":0,\"new_col\":0}})</td><td>null</td><td>null</td></tr></tbody></table></div>"]}}],"execution_count":49},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":50},{"cell_type":"markdown","source":["### Explain about scalable metadata handling"],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":52}],"metadata":{"name":"DELTA_LAKE_DEMO","notebookId":891795827403111},"nbformat":4,"nbformat_minor":0}
